================================================================================
                         SURVEY DATA VALIDATOR
                    Professional Land Survey QC Tool
================================================================================

                    "Catch errors before they become problems"

================================================================================
                              WHAT IS THIS?
================================================================================

Survey Data Validator is a web-based quality control tool designed specifically
for land surveyors, civil engineers, and geospatial professionals. It takes
raw survey coordinate data and performs automated validation checks to detect
common errors BEFORE that data gets used in construction, mapping, or legal
boundary work.

Think of it as a spell-checker for coordinates. You wouldn't submit a legal
document without spell-checking it firstâ€”this tool does the same thing for
your survey data.

================================================================================
                           WHY DOES IT EXIST?
================================================================================

Survey errors are expensive. A missed duplicate point can cause confusion on
site. A traverse that doesn't close properly might indicate a blown setup or
misread rod. An outlier could be a typo or a GPS glitch. These errors, when
caught late, can cost thousands of dollars to fix and weeks of delay.

This tool catches these issues in seconds, right after data collection, when
fixing them is still cheap and easy.

Real-world problems this tool catches:

    âŒ Duplicated point IDs (same name, different coordinates)
    âŒ Near-duplicate points (two shots at basically the same spot)
    âŒ Traverse misclosure beyond acceptable tolerance
    âŒ Outlier points that are statistically suspicious
    âŒ Missing or malformed coordinate data
    âŒ Invalid point types or naming

================================================================================
                        HOW DOES IT WORK?
================================================================================

1. INPUT YOUR DATA
   - Paste CSV directly from Excel or survey software
   - Upload a .csv or .txt file
   - Enter points manually in the table
   - Supports headerless data with smart column detection

2. CHOOSE YOUR TOLERANCE
   - Survey Grade (1mm) â€” for precise control work
   - Engineering (1cm) â€” for typical construction surveys
   - Mapping (10cm) â€” for GIS and reconnaissance work

3. RUN VALIDATION
   The engine performs 8+ concurrent checks in parallel:
   
   âœ“ Input Validation â€” Are coordinates valid numbers?
   âœ“ Duplicate Detection â€” Same point ID used twice?
   âœ“ Near-Duplicate Analysis â€” Two points within 1cm?
   âœ“ Outlier Detection â€” Points far from the centroid?
   âœ“ Traverse Geometry â€” Are legs reasonable length?
   âœ“ Traverse Closure â€” Does it close mathematically?
   âœ“ Bearing Analysis â€” Any suspicious angle jumps?
   âœ“ Statistical Summary â€” Overall data health metrics

4. GET YOUR REPORT
   - Overall PASS / WARNING / FAIL status
   - Confidence score (0-100%)
   - Interactive visualization with zoom, pan, measure
   - Click any issue to jump to the source row
   - Export as JSON, CSV, or PNG plot

================================================================================
                    TRAVERSE CLOSURE EXPLAINED
================================================================================

When you run a traverse, you start at a known point and take a series of
shots, eventually returning to the starting point (closed traverse) or to
another known control point (link traverse).

Due to measurement errors, you never close perfectly. The MISCLOSURE is the
difference between where you should be and where your measurements say you are.

                    Start (Known) â”€â”€â†’ T2 â”€â”€â†’ T3 â”€â”€â†’ T4
                         â†‘                              â†“
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ T6 â†â”€â”€ T5 â†â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†‘
                               Computed end
                               (should be exactly Start)

CLOSURE RATIO expresses misclosure relative to total distance:

    Closure Ratio = Total Traverse Length Ã· Linear Misclosure

Example:
    - Total length walked: 500 meters
    - Misclosure: 0.05 meters (50mm)
    - Ratio = 500 / 0.05 = 10,000
    - Expressed as "1:10,000" â€” meaning 1mm error per 10m of traverse

Industry standards:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Rating           â”‚ Ratio         â”‚ Use Case                        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Excellent        â”‚ 1:10,000+     â”‚ Control networks, legal bounds  â”‚
    â”‚ Good             â”‚ 1:5,000+      â”‚ Construction, boundary retraces â”‚
    â”‚ Acceptable       â”‚ 1:3,000+      â”‚ Preliminary work, topo surveys  â”‚
    â”‚ Poor             â”‚ <1:3,000      â”‚ Needs investigation             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
                    BOWDITCH ADJUSTMENT EXPLAINED
================================================================================

When your traverse has acceptable misclosure, you can ADJUST it to make it
close perfectly. The Bowditch method (also called Compass Rule) distributes
the error proportionally based on leg distances.

The idea: longer legs contribute more to total error, so they get more of
the correction.

For each point:

    Easting Correction = (Leg Distance / Total Distance) Ã— Î”E misclosure
    Northing Correction = (Leg Distance / Total Distance) Ã— Î”N misclosure

After adjustment, the traverse closes exactly to zero misclosure. The
"Adjusted Coordinates" toggle on the visualization shows these corrected
positions overlaid on the original data.

================================================================================
                         CONFIDENCE SCORE
================================================================================

The confidence score (0-100%) represents overall data quality. It's NOT a
statistical confidence intervalâ€”it's a heuristic based on:

    Base Score: 100%
    
    Deductions:
        - Each ERROR found: -15 points
        - Each WARNING found: -5 points
        - Each INFO notice: -1 point
    
    Minimum: 0%

A score of 85%+ generally indicates data ready for deliverable use.
A score below 70% suggests issues that should be investigated.

================================================================================
                        POINT TYPES EXPLAINED
================================================================================

CONTROL POINTS (â–² green triangles)
    Known, fixed reference points with published coordinates. These are your
    "truth"â€”typically monumented points from a geodetic network, or established
    project control.

TRAVERSE POINTS (â— blue circles)
    Sequential stations in your traverse. These are the setups you occupied
    to run your survey. Order mattersâ€”the closure algorithm assumes they're
    in path sequence.

DETAIL POINTS (â—† gray diamonds)
    Everything else: topographic shots, boundary corners, building corners,
    utility locates. These are validated for duplicates and outliers but not
    included in traverse closure calculations.

================================================================================
                    VISUALIZATION FEATURES
================================================================================

The interactive plot shows your survey spatially:

CONTROLS:
    ï¼‹ / âˆ’       Zoom in/out
    â†º            Reset view (also clears measurement)
    ğŸ“           Measurement mode (click two points for distance/bearing)
    ğŸ·ï¸ Labels    Toggle point ID display
    âœ“ Adjusted   Show Bowditch-adjusted coordinates
    ğŸ“¥ Export    Download as PNG image

INTERACTION:
    - Drag to pan when zoomed
    - Scroll wheel to zoom
    - Hover any point for detailed tooltip
    - Click point to see full info
    - Minimap appears when zoomed (shows viewport position)

CARTOGRAPHIC ELEMENTS:
    - Professional scale bar with alternating segments
    - North arrow in compass style
    - Legend showing point type symbols
    - Grid lines for coordinate reference

================================================================================
                    EDITING DATA
================================================================================

The input table is fully editable:

KEYBOARD SHORTCUTS:
    Tab          Move to next cell
    Shift+Tab    Move to previous cell
    Enter        Move down (adds new row at bottom)
    Arrow Up     Move to cell above
    Arrow Down   Move to cell below

CLICK-TO-EDIT:
    Click any cell to edit directly. Changes are reflected immediately.

JUMP TO ISSUES:
    After validation, click any issue row in the report. The tool will:
    1. Scroll to the input table
    2. Expand the table if collapsed
    3. Highlight the affected row(s) with blue pulse
    4. Focus the first input for immediate editing

================================================================================
                    CSV IMPORT
================================================================================

Two ways to import:

1. PASTE CSV
   - Click "Paste CSV"
   - Paste data from Excel, Notepad, or survey software
   - Toggle "First row is header" as appropriate
   - Preview shows detected structure
   - Click "Import" to load into table

2. UPLOAD FILE
   - Click "Upload File"
   - Select .csv or .txt file
   - Same preview and column mapping flow

SMART COLUMN DETECTION:
   For headerless data, the tool analyzes the first row:
   - Columns with large numbers (>10,000) â†’ likely coordinates
   - First large column â†’ Easting
   - Second large column â†’ Northing
   - First text column â†’ Point ID
   - Remaining number column â†’ Height

POINT TYPE INFERENCE:
   If no Type column, names are analyzed:
   - Contains "CP", "CON", "CTRL", "BM" â†’ Control
   - Contains "T" followed by digits â†’ Traverse
   - Everything else â†’ Detail

================================================================================
                    TOLERANCE PRESETS
================================================================================

SURVEY GRADE (1mm)
    - Duplicate threshold: 0.001m
    - Near-duplicate: 0.010m
    - Used for: precise control, deformation monitoring

ENGINEERING (1cm)
    - Duplicate threshold: 0.010m
    - Near-duplicate: 0.100m
    - Used for: construction layout, boundary surveys

MAPPING (10cm)
    - Duplicate threshold: 0.100m
    - Near-duplicate: 1.000m
    - Used for: GIS data capture, reconnaissance

================================================================================
                    TECHNICAL DETAILS
================================================================================

COORDINATE SYSTEM:
    This tool works with PROJECTED coordinates (meters). It does NOT support
    geographic coordinates (latitude/longitude). Your data should be in a
    local grid, state plane, UTM, or similar projection.

TRAVERSE DETECTION:
    The tool automatically identifies if you have a closed traverse (T1=T6)
    or link traverse (T1â†’Control, T6â†’Control). It detects this by checking
    if traverse endpoints match control point coordinates within tolerance.

OUTLIER DETECTION:
    Uses standard deviation from centroid. Points beyond 3Ïƒ (three standard
    deviations) are flagged as potential outliers. This works best for
    clustered detail points; linear traverses may trigger false positives.

CONCURRENT PROCESSING:
    All validation checks run in parallel using Go's goroutines. A typical
    500-point dataset validates in under 100 milliseconds.

================================================================================
                    DEPLOYMENT
================================================================================

This tool runs as a serverless application on Vercel:

    Frontend: Static HTML/CSS/JavaScript (single file, ~3000 lines)
    Backend:  Go 1.21 serverless functions
    API:      RESTful JSON at /api/v1/validate

No database. No user accounts. No data storage. Your survey data stays in
your browser and is only sent to the validation API during processing.

================================================================================
                    LIMITATIONS
================================================================================

- Maximum ~1000 points per validation (browser performance)
- Traverse must be sequential (T1 â†’ T2 â†’ T3 â†’ ... â†’ Tn)
- No support for leveling runs (vertical-only traverses)
- Outlier detection assumes roughly clustered data
- No transformation between coordinate systems
- No support for angular observations (angles, bearings)

================================================================================
                    FUTURE ENHANCEMENTS
================================================================================

Potential roadmap items:

    â–¡ Level run validation (differential leveling)
    â–¡ Angular misclosure checks (when observations provided)
    â–¡ Coordinate transformation (between systems)
    â–¡ Project templates (save/load configurations)
    â–¡ Batch processing (multiple files)
    â–¡ PDF report generation
    â–¡ Comparison mode (before/after datasets)

================================================================================
                    CREDITS
================================================================================

Built with:
    - Go 1.21 (backend validation engine)
    - Vanilla JavaScript (no frameworks, no dependencies)
    - HTML5 Canvas (visualization)
    - Vercel (serverless hosting)

Survey mathematics based on standard texts:
    - "Elementary Surveying" by Ghilani & Wolf
    - "Adjustment Computations" by Ghilani

================================================================================
                    SUMMARY
================================================================================

Survey Data Validator is your pre-flight checklist for survey data. Before
you submit coordinates to a client, import them into CAD, or file a plat,
run them through this tool. It takes 30 seconds and could save you from an
embarrassing (and expensive) mistake.

    âœ“ Catches duplicates
    âœ“ Validates traverse closure
    âœ“ Flags outliers
    âœ“ Shows spatial visualization
    âœ“ Computes adjusted coordinates
    âœ“ Exports professional reports

No installation. No login. Just paste your data and validate.

================================================================================
                    https://surveyvalidator.vercel.app
================================================================================
